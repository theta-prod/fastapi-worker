# [Tutoial] fastapi-worker with transformer Model

- **Metadata** : `type: Tutoial` `scope: API, Backend, fastapi` 
- **Techs Need** : `python` `fastapi`
- **Status**: `need-review`
<br/><br/>

## âœ¨ You should already know
- huggingface
- transformer
- FastAPI

ğŸ‘©â€ğŸ’» ğŸ‘¨â€ğŸ’»

## âœ¨ About the wiki
- `Situation:` æä¾›NLUçš„æœå‹™æ¥å£ï¼Œæ–¹ä¾¿èˆ‡å„æœå‹™é€²è¡Œä¸²æ¥ã€‚
- `Target:` æä¾›APIæ¥å£å’Œæ–‡ä»¶æ–¹ä¾¿å°æ¥ã€‚
- `Index:`

| Sub title | decription | memo |
| ------ | ------ | ------ |
| API | ä½¿ç”¨FastAPIä¾†å»ºç½®API | åŒ…å«æ–‡ä»¶ä½¿ç”¨å’Œå®šç¾© |
| MODEL | å¾huggingfaceä¸Šä¸‹è¼‰æœå‹™ä¾†å¯¦ç¾APIæœå‹™ | åŒ…å«è¼‰å…¥æ¨¡å‹èˆ‡é©…å‹•æ¨¡å‹ |


---
<br>

### **API**
> ä½¿ç”¨FastAPIä¾†å»ºç½®API

####  ğŸ“ å®šç¾©APIè¼¸å…¥èˆ‡è¼¸å‡ºçš„å…§å®¹
é€™é‚Šè«‹è¦å¥½å¥½å®šç¾©ï¼Œä¹‹å¾ŒFastAPIæœƒæ ¹æ“šé€™äº›å®šç¾©ä¾†ç”¢ç”Ÿç·šä¸Šæ–‡ä»¶ï¼Œç·šä¸Šæ–‡ä»¶å¯ä»¥å”åŠ©ç›´æ¥é€éç¶²é ä¾†æ‰“å‡ºè«‹æ±‚ã€æ¸¬è©¦API

- Input(Body)
```
from typing import NewType, TypedDict

corpus = NewType("corpus", str)
class Body(TypedDict):
    corpus: corpus
```


- Output(JsonResponMsg)
```
from typing import TypedDict, NewType, List, Dict

class modelResult(TypedDict):
    word: str
    entity: str

class JsonResponBase(TypedDict):
    status: int

class JsonResponMsg(JsonResponBase):
    result: List[modelResult]
```

####  ğŸ“ æœå‹™æœ¬é«”

- è¨­å®šä¼ºæœå™¨åŸºæœ¬å…§å®¹
```
import uvicorn
from fastapi import FastAPI
from type.response import JsonResponMsg
from type.client import Body
from typing import List
from model import runModel, ModelResult

app = FastAPI()


@app.post("/model", response_model=JsonResponMsg)
async def newUserById(body: Body) -> JsonResponMsg:
    print(body)
    result: List[ModelResult] = runModel(data=body['corpus'])
    return JsonResponMsg(status=200, result=result)


uvicorn.run(app, host="0.0.0.0", port=8080)
```

- å•Ÿå‹•ä¼ºæœå™¨(æ¸¬è©¦ç”¨ï¼Œæ­£å¼ä½¿ç”¨æ™‚å»ºè­°ä½¿ç”¨dockerä¾†å»ºç½®)
```
python main.py
```

- å•Ÿå‹•ä¼ºæœå™¨(docker)
```
sudo docker-compose up -d
```

- ç·šä¸Šæ–‡ä»¶
```
http://127.0.0.1:8080/docs/
```

### **MODEL**
> å¾huggingfaceä¸Šä¸‹è¼‰æœå‹™ä¾†å¯¦ç¾APIæœå‹™ã€‚

é€™é‚Šæˆ‘å€‘ç”¨[æ–·å¥æ¨¡å‹: theta/sentcore](https://huggingface.co/theta/sentcore)é€²è¡Œç¤ºç¯„ã€‚


####  ğŸ“ è¼‰å…¥æ¨¡å‹
é€™é‚Šæˆ‘å€‘è¼‰å…¥æ¨¡å‹å’Œç›¸é—œé…å¥—å¥—ä»¶ã€‚ä¸¦ä½¿ç”¨`TokenClassificationPipeline`ä¾†é©…å‹•æ¨¡å‹
```
from transformers import AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline
from transformers.models.bert.tokenization_bert_fast import BertTokenizerFast
from transformers.models.bert.modeling_bert import BertForTokenClassification

##
def getTokenizer(tag: str) -> BertTokenizerFast:
    return AutoTokenizer.from_pretrained(tag)


def getModel(tag: str, num_labels: int = 4) -> BertForTokenClassification:
    return AutoModelForTokenClassification.from_pretrained(
        tag, num_labels=num_labels)


##
tokenizer: BertTokenizerFast = getTokenizer("bert-base-chinese")
model: BertForTokenClassification = getModel("theta/sentcore")
classifier: TokenClassificationPipeline = TokenClassificationPipeline(
    model=model, tokenizer=tokenizer)
```

####  ğŸ“ æ¨¡å‹è™•ç†
è¼‰å…¥å®Œæ¨¡å‹ï¼Œå»ºè­°æ ¹æ“šæ¨¡å‹çš„è¼¸å‡ºå»å®šç¾©ç‰©ä»¶ï¼Œå¢åŠ ç³»çµ±ç©©å®šæ€§

- å»ºç«‹é©…å‹•æ¨¡å‹çš„æ–¹æ³• 
```
# type
class Letter(TypedDict):
    entity: str
    word: str
    score: int
    index: int
    start: int
    end: int


class ModelResult(TypedDict):
    entity: str
    word: str

def runModel(data: str) -> List[ModelResult]:
    modelResult: List[Letter] = classifier(data)
    return [{
        "word": row["word"],
        "entity": row["entity"]
    } for row in modelResult]
```

- æ¸¬è©¦æ¨¡å‹

```
runModel("æ“šäº†è§£å°å—å¸‚è­¦äºŒåˆ†å±€æ°‘æ¬Šæ‰€è­¦å“¡å‡ƒæ˜èª æ›¹ç‘å‚‘æ…˜é­å‰²å–‰æ®‰è·å«ŒçŠ¯æ—ä¿¡å¾ç¶“é18å°æ™‚çš„é€ƒäº¡23æ—¥æ¸…æ™¨4æ™‚36åˆ†åœ¨æ–°ç«¹çš„å’Œæ¬£å®¢é‹ç«™è½ç¶²")

>>> [
	{"word": "æ“š" , "entity": "|"},
	{"word": "äº†" , "entity": ""},
	{"word": "è§£" , "entity": "|"},
	...
]

```

